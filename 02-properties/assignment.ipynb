{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-title",
   "metadata": {},
   "source": [
    "# Week 2: Network Properties — Assignment\n",
    "\n",
    "**Learning objectives** — In this assignment you will:\n",
    "\n",
    "- Rank nodes by degree centrality\n",
    "- Compute betweenness centrality using NetworkX\n",
    "- Implement local clustering coefficient from scratch\n",
    "- Implement closeness centrality from scratch\n",
    "- Measure the correlation between centrality measures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-grading",
   "metadata": {},
   "source": [
    "## Grading\n",
    "\n",
    "| Section | Part | Function | Points |\n",
    "|---------|------|----------|--------|\n",
    "| 1 | Degree Centrality | `top_k_by_degree(G, k)` | 10 |\n",
    "| 2 | Betweenness | `compute_betweenness(G, normalized)` | 15 |\n",
    "| 3 | Clustering | `local_clustering(G, node)` | 20 |\n",
    "| 4 | Closeness | `closeness_centrality(G, node)` | 10 |\n",
    "| 5 | Correlation | `centrality_correlation(G)` | 15 |\n",
    "| 6 | PageRank | `compute_pagerank(G, alpha, max_iter)` | 10 |\n",
    "| 7 | Assortativity | `degree_assortativity(G)` | 10 |\n",
    "| — | Written Questions | — | 10 |\n",
    "| | **Total** | | **100** |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-before-you-start",
   "metadata": {},
   "source": [
    "## Before You Start\n",
    "\n",
    "This assignment builds on the Week 2 lab. Make sure you are comfortable with:\n",
    "\n",
    "- **Degree distribution** — how to read linear and log-log plots (Lab Section 2)\n",
    "- **Clustering coefficient** — the formula C = 2·triangles / k(k-1) and what it measures (Lab Section 4)\n",
    "- **Three centrality measures** — degree (popularity), betweenness (brokerage), closeness (proximity) and how they can disagree (Lab Section 5)\n",
    "- **PageRank** — recursive importance via random walks, damping factor α (Lab Section 6)\n",
    "- **Assortativity** — do hubs connect to hubs? The degree correlation coefficient r (Lab Section 7)\n",
    "\n",
    "You will implement clustering and closeness **from scratch** — review the formulas in the lab before starting Sections 3-4. Sections 6-7 require implementing PageRank and assortativity from scratch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from netsci.loaders import load_graph\n",
    "from netsci.utils import SEED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-data",
   "metadata": {},
   "outputs": [],
   "source": [
    "G_karate = load_graph(\"karate\")\n",
    "G_fb = load_graph(\"facebook\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-sec1-title",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 1: Degree Centrality (10 pts)\n",
    "\n",
    "Return the top-*k* nodes by degree as a list of `(node, degree)` tuples, sorted from highest to lowest degree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-sec1-stub",
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_k_by_degree(G, k=5):\n",
    "    \"\"\"Return the top-k nodes by degree.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    G : nx.Graph\n",
    "    k : int\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    list of (node, degree) tuples, sorted descending by degree.\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-sec1-test",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Validation ---\n",
    "_top5 = top_k_by_degree(G_karate, 5)\n",
    "assert len(_top5) == 5\n",
    "# Degrees should be descending\n",
    "assert all(_top5[i][1] >= _top5[i + 1][1] for i in range(len(_top5) - 1))\n",
    "# Node 33 or 0 should be in top 5 (they are the highest-degree nodes)\n",
    "_top_nodes = {n for n, d in _top5}\n",
    "assert 33 in _top_nodes or 0 in _top_nodes\n",
    "print(f\"Top 5 in Karate: {_top5}\")\n",
    "print(\"Section 1 passed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-sec2-title",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 2: Betweenness Centrality (15 pts)\n",
    "\n",
    "Compute betweenness centrality for all nodes using NetworkX's implementation.\n",
    "Return a dictionary mapping each node to its betweenness centrality value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-sec2-stub",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_betweenness(G, normalized=True):\n",
    "    \"\"\"Compute betweenness centrality for all nodes.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    G : nx.Graph\n",
    "    normalized : bool, default True\n",
    "        If True, normalize by 2/((n-1)(n-2)) for undirected graphs.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict mapping node -> float\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-sec2-test",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Validation ---\n",
    "_bet = compute_betweenness(G_karate, normalized=True)\n",
    "_bet_nx = nx.betweenness_centrality(G_karate, normalized=True)\n",
    "assert isinstance(_bet, dict)\n",
    "assert len(_bet) == G_karate.number_of_nodes()\n",
    "for node in G_karate.nodes():\n",
    "    assert abs(_bet[node] - _bet_nx[node]) < 1e-6, f\"Mismatch at node {node}\"\n",
    "print(\"Section 2 passed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-sec3-title",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 3: Local Clustering Coefficient (20 pts)\n",
    "\n",
    "Implement the **local clustering coefficient** for a single node **from scratch** (do not call `nx.clustering`).\n",
    "\n",
    "Recall: for a node $v$ with degree $k_v$, the clustering coefficient is:\n",
    "\n",
    "$$C_v = \\frac{2 \\times |\\text{edges among neighbors of } v|}{k_v (k_v - 1)}$$\n",
    "\n",
    "If $k_v < 2$, return 0.0 (no triangle is possible)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-sec3-stub",
   "metadata": {},
   "outputs": [],
   "source": [
    "def local_clustering(G, node):\n",
    "    \"\"\"Compute the local clustering coefficient of a node from scratch.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    G : nx.Graph\n",
    "    node : any hashable\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-sec3-test",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Validation ---\n",
    "for node in G_karate.nodes():\n",
    "    _mine = local_clustering(G_karate, node)\n",
    "    _nx_val = nx.clustering(G_karate, node)\n",
    "    assert abs(_mine - _nx_val) < 1e-6, f\"Node {node}: got {_mine}, expected {_nx_val}\"\n",
    "print(\"All 34 nodes match nx.clustering — Section 3 passed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-sec4-title",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 4: Closeness Centrality (10 pts)\n",
    "\n",
    "Implement **closeness centrality** for a single node **from scratch** (do not call `nx.closeness_centrality`).\n",
    "\n",
    "$$C_C(v) = \\frac{n - 1}{\\sum_{u \\neq v} d(v, u)}$$\n",
    "\n",
    "where $d(v, u)$ is the shortest path length from $v$ to $u$, and $n$ is the number of nodes.\n",
    "\n",
    "You may use `nx.shortest_path_length` to get distances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-sec4-stub",
   "metadata": {},
   "outputs": [],
   "source": [
    "def closeness_centrality(G, node):\n",
    "    \"\"\"Compute closeness centrality for a single node from scratch.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    G : nx.Graph\n",
    "    node : any hashable\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-sec4-test",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Validation ---\n",
    "for node in G_karate.nodes():\n",
    "    _mine = closeness_centrality(G_karate, node)\n",
    "    _nx_val = nx.closeness_centrality(G_karate, node)\n",
    "    assert abs(_mine - _nx_val) < 1e-6, f\"Node {node}: got {_mine}, expected {_nx_val}\"\n",
    "print(\"All 34 nodes match nx.closeness_centrality — Section 4 passed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-sec5-title",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 5: Centrality Correlation (15 pts)\n",
    "\n",
    "Compute the **Pearson correlation** between degree centrality and betweenness centrality across all nodes.\n",
    "\n",
    "Use `np.corrcoef` or the formula directly. Return a single float."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-sec5-stub",
   "metadata": {},
   "outputs": [],
   "source": [
    "def centrality_correlation(G):\n",
    "    \"\"\"Compute Pearson r between degree and betweenness centrality.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    G : nx.Graph\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float  (Pearson correlation coefficient)\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-sec5-test",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Validation ---\n",
    "_r = centrality_correlation(G_karate)\n",
    "assert isinstance(_r, float)\n",
    "# Degree and betweenness are positively correlated in most real networks\n",
    "assert _r > 0.3, f\"Expected positive correlation, got {_r}\"\n",
    "assert _r <= 1.0\n",
    "\n",
    "# Verify against direct computation\n",
    "_deg = nx.degree_centrality(G_karate)\n",
    "_bet = nx.betweenness_centrality(G_karate)\n",
    "_nodes = list(G_karate.nodes())\n",
    "_d = [_deg[n] for n in _nodes]\n",
    "_b = [_bet[n] for n in _nodes]\n",
    "_expected_r = float(np.corrcoef(_d, _b)[0, 1])\n",
    "assert abs(_r - _expected_r) < 1e-6, f\"Got {_r}, expected {_expected_r}\"\n",
    "print(f\"Pearson r (degree vs betweenness) = {_r:.4f}\")\n",
    "print(\"Section 5 passed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-sec6-title",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 6: PageRank from Scratch (10 pts)\n",
    "\n",
    "Implement PageRank using the **power iteration** method:\n",
    "\n",
    "1. Initialize: every node gets score 1/n\n",
    "2. Repeat for `max_iter` iterations:\n",
    "   - For each node v: new_score(v) = (1 - alpha) / n + alpha * sum(score(u) / degree(u) for u in neighbors of v)\n",
    "3. Return the final scores as a dictionary\n",
    "\n",
    "The damping factor `alpha` (default 0.85) controls how likely the random surfer is to follow a link vs jump to a random page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-sec6-stub",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_pagerank(G, alpha=0.85, max_iter=100):\n",
    "    \"\"\"Compute PageRank using power iteration.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    G : nx.Graph\n",
    "    alpha : float, default 0.85\n",
    "        Damping factor.\n",
    "    max_iter : int, default 100\n",
    "        Number of power iterations.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict mapping node -> float (PageRank score)\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-sec6-test",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Validation ---\n",
    "_pr = compute_pagerank(G_karate, alpha=0.85, max_iter=100)\n",
    "_pr_nx = nx.pagerank(G_karate, alpha=0.85, max_iter=100)\n",
    "assert isinstance(_pr, dict)\n",
    "assert len(_pr) == G_karate.number_of_nodes()\n",
    "# Check values are close to NetworkX (tolerance for convergence differences)\n",
    "for node in G_karate.nodes():\n",
    "    assert abs(_pr[node] - _pr_nx[node]) < 0.005, (\n",
    "        f\"Node {node}: got {_pr[node]:.6f}, expected {_pr_nx[node]:.6f}\"\n",
    "    )\n",
    "# Sum should be approximately 1\n",
    "assert abs(sum(_pr.values()) - 1.0) < 0.01, (\n",
    "    f\"Sum = {sum(_pr.values()):.4f}, expected ~1.0\"\n",
    ")\n",
    "print(f\"Top 3 by PageRank: {sorted(_pr, key=_pr.get, reverse=True)[:3]}\")\n",
    "print(\"Section 6 passed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-sec7-title",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 7: Degree Assortativity (10 pts)\n",
    "\n",
    "Implement the **degree assortativity coefficient** from scratch using Pearson correlation of degrees at edge endpoints.\n",
    "\n",
    "For each edge (u, v) in an undirected graph, include **both** orderings: (deg(u), deg(v)) and (deg(v), deg(u)). This symmetrization matches Newman's original formula. Then compute the Pearson correlation coefficient between the two degree sequences using `np.corrcoef`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-sec7-stub",
   "metadata": {},
   "outputs": [],
   "source": [
    "def degree_assortativity(G):\n",
    "    \"\"\"Compute degree assortativity coefficient from scratch.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    G : nx.Graph\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float (Pearson correlation of degrees at edge endpoints)\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-sec7-test",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Validation ---\n",
    "_r = degree_assortativity(G_karate)\n",
    "_r_nx = nx.degree_assortativity_coefficient(G_karate)\n",
    "assert isinstance(_r, float)\n",
    "assert abs(_r - _r_nx) < 0.05, f\"Got {_r:.4f}, expected {_r_nx:.4f}\"\n",
    "\n",
    "# Test on Facebook too\n",
    "_r_fb = degree_assortativity(G_fb)\n",
    "_r_fb_nx = nx.degree_assortativity_coefficient(G_fb)\n",
    "assert abs(_r_fb - _r_fb_nx) < 0.05, (\n",
    "    f\"Facebook: got {_r_fb:.4f}, expected {_r_fb_nx:.4f}\"\n",
    ")\n",
    "\n",
    "print(f\"Karate:   r = {_r:.4f} (nx: {_r_nx:.4f})\")\n",
    "print(f\"Facebook: r = {_r_fb:.4f} (nx: {_r_fb_nx:.4f})\")\n",
    "print(\"Section 7 passed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-written-title",
   "metadata": {},
   "source": [
    "---\n",
    "## Written Questions (10 pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-q1",
   "metadata": {},
   "source": [
    "### Question 1 (5 pts)\n",
    "\n",
    "In the US power grid, what does it mean for a node to have high **betweenness centrality**?\n",
    "What would happen to the network if that node (substation) failed?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-q1-hints",
   "metadata": {},
   "source": [
    "*Hints to guide your thinking:*\n",
    "- *Betweenness counts how many shortest paths pass **through** a node. In a sparse, tree-like network like the power grid, what happens when a node on the \"trunk\" is removed?*\n",
    "- *Think about the difference between a node with many local connections (high degree) vs. a node that sits on the only path between two regions (high betweenness).*\n",
    "- *Consider real infrastructure: if a key highway interchange fails, what happens to traffic flow?*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-a1",
   "metadata": {},
   "source": [
    "**Your Answer:**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-q2",
   "metadata": {},
   "source": [
    "### Question 2 (5 pts)\n",
    "\n",
    "Can a node have **high degree** but **low betweenness**? Describe a network structure where this happens and explain why."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-q2-hints",
   "metadata": {},
   "source": [
    "*Hints to guide your thinking:*\n",
    "- *Imagine a \"star\" subgraph: one central node connected to 50 leaf nodes, all of whom also connect to a separate hub. The central node has high degree — but do shortest paths between other nodes need to pass through it?*\n",
    "- *Betweenness is about being on shortest paths **between other pairs**. A node can be popular (many friends) yet replaceable (all its friends also know each other directly).*\n",
    "- *Think about the Karate Club: node 33 has the highest degree (17) — does it also have the highest betweenness? Check and explain why or why not.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-a2",
   "metadata": {},
   "source": [
    "**Your Answer:**\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
